

cls_num = 10

batch_size = 128
epoches = 140
#  epoches = 30


# optimizer params
weight_decay = 1e-4
lr_factor = 0.7
lr_steps = 3000
lr_stop_val = 1e-4
learning_rate = 1e-1
#  learning_rate = 1e-2

#  optimizer = 'adam'
optimizer = 'sgd'


# The best now is: 1e-2 1e-4 0.7 2500

generate_batches = 1


